{
for (j in 1:p){
db[j] = sum(R*X[,j])
}
j=which.max(abs(db))
beta[j]=beta[j]+db[j]*epsilon
R=R-X[,j]*db[j]*epsilon
beta_all[,t] = beta
}
matplot(t(matrix(rep(1, p), nrow = 1)%*%abs(beta_all)), t(beta_all), type = 'l')
n = 50
p = 200
s = 10
T = 10
lambda_all = (100:1)*10
L = length(lambda_all)
db = matrix(rep(0, p), nrow = p)
X = matrix(rnorm(n*p), nrow=n)
beta_true = matrix(rep(0, p), nrow = p)
beta_true[1:s] = 1:s
Y = X %*% beta_true + rnorm(n)
beta = matrix(rep(0, p), nrow = p)
beta_all = matrix(rep(0, p*L), nrow = p)
err = rep(0, L)
R = Y
ss = rep(0, p)
for (j in 1:p)
ss[j] = sum(X[, j]^2)
for (l in 1:L)
{
lambda = lambda_all[l]
for (t in 1:T)
{
for (j in 1:p)
{
db = sum(R*X[, j])/ss[j]
b = beta[j]+db
b=sign(b)*max(0,abs(b)-lambda/ss[j])
db=b-beta[j]
R=R-X[,j]*db
beta[j]=b
}
}
beta_all[, l] = beta
err[l] = sum((beta-beta_true)^2)
}
par(mfrow=c(1,3))
matplot(t(matrix(rep(1, p), nrow = 1)%*%abs(beta_all)), t(beta_all), type = 'l',main='LASSO BOOSTING')
plot(lambda_all, err, type = 'l',main='LASSO ERROR ESTIMATION')
T = 6000
epsilon = .0001
beta = matrix(rep(0, p), nrow = p)
db = matrix(rep(0, p), nrow = p)
beta_all = matrix(rep(0, p*T), nrow = p)
R = Y
for (t in 1:T)
{
for (j in 1:p){
db[j] = sum(R*X[,j])
}
j=which.max(abs(db))
beta[j]=beta[j]+db[j]*epsilon
R=R-X[,j]*db[j]*epsilon
beta_all[,t] = beta
}
matplot(t(matrix(rep(1, p), nrow = 1)%*%abs(beta_all)), t(beta_all), type = 'l',main='STAGEWISE REGRESSION')
n = 50
p = 200
s = 10
T = 10
lambda_all = (100:1)*10
L = length(lambda_all)
db = matrix(rep(0, p), nrow = p)
X = matrix(rnorm(n*p), nrow=n)
beta_true = matrix(rep(0, p), nrow = p)
beta_true[1:s] = 1:s
Y = X %*% beta_true + rnorm(n)
beta = matrix(rep(0, p), nrow = p)
beta_all = matrix(rep(0, p*L), nrow = p)
err = rep(0, L)
R = Y
ss = rep(0, p)
for (j in 1:p)
ss[j] = sum(X[, j]^2)
for (l in 1:L)
{
lambda = lambda_all[l]
for (t in 1:T)
{
for (j in 1:p)
{
db = sum(R*X[, j])/ss[j]
b = beta[j]+db
b=sign(b)*max(0,abs(b)-lambda/ss[j])
db=b-beta[j]
R=R-X[,j]*db
beta[j]=b
}
}
beta_all[, l] = beta
err[l] = sum((beta-beta_true)^2)
}
par(mfrow=c(1,3))
matplot(t(matrix(rep(1, p), nrow = 1)%*%abs(beta_all)), t(beta_all), type = 'l',main='LASSO BOOSTING')
plot(lambda_all, err, type = 'l',main='LASSO ERROR ESTIMATION')
T = 6000
epsilon = .0001
beta = matrix(rep(0, p), nrow = p)
db = matrix(rep(0, p), nrow = p)
beta_all = matrix(rep(0, p*T), nrow = p)
R = Y
for (t in 1:T)
{
for (j in 1:p){
db[j] = sum(R*X[,j])
}
j=which.max(abs(db))
beta[j]=beta[j]+db[j]*epsilon
R=R-X[,j]*db[j]*epsilon
beta_all[,t] = beta
}
matplot(t(matrix(rep(1, p), nrow = 1)%*%abs(beta_all)), t(beta_all), type = 'l',main='STAGEWISE REGRESSION',xlab='N')
n = 50
p = 200
s = 10
T = 10
lambda_all = (100:1)*10
L = length(lambda_all)
db = matrix(rep(0, p), nrow = p)
X = matrix(rnorm(n*p), nrow=n)
beta_true = matrix(rep(0, p), nrow = p)
beta_true[1:s] = 1:s
Y = X %*% beta_true + rnorm(n)
beta = matrix(rep(0, p), nrow = p)
beta_all = matrix(rep(0, p*L), nrow = p)
err = rep(0, L)
R = Y
ss = rep(0, p)
for (j in 1:p)
ss[j] = sum(X[, j]^2)
for (l in 1:L)
{
lambda = lambda_all[l]
for (t in 1:T)
{
for (j in 1:p)
{
db = sum(R*X[, j])/ss[j]
b = beta[j]+db
b=sign(b)*max(0,abs(b)-lambda/ss[j])
db=b-beta[j]
R=R-X[,j]*db
beta[j]=b
}
}
beta_all[, l] = beta
err[l] = sum((beta-beta_true)^2)
}
par(mfrow=c(1,3))
matplot(t(matrix(rep(1, p), nrow = 1)%*%abs(beta_all)), t(beta_all), type = 'l',main='LASSO BOOSTING',xlab='N',ylab='Beta')
plot(lambda_all, err, type = 'l',main='LASSO ERROR ESTIMATION',xlab='Lambda',ylab='Error')
T = 6000
epsilon = .0001
beta = matrix(rep(0, p), nrow = p)
db = matrix(rep(0, p), nrow = p)
beta_all = matrix(rep(0, p*T), nrow = p)
R = Y
for (t in 1:T)
{
for (j in 1:p){
db[j] = sum(R*X[,j])
}
j=which.max(abs(db))
beta[j]=beta[j]+db[j]*epsilon
R=R-X[,j]*db[j]*epsilon
beta_all[,t] = beta
}
matplot(t(matrix(rep(1, p), nrow = 1)%*%abs(beta_all)), t(beta_all), type = 'l',main='STAGEWISE REGRESSION',xlab='N',ylab='Beta')
n = 50
p = 200
s = 10
T = 10
lambda_all = (100:1)*10
L = length(lambda_all)
db = matrix(rep(0, p), nrow = p)
X = matrix(rnorm(n*p), nrow=n)
beta_true = matrix(rep(0, p), nrow = p)
beta_true[1:s] = 1:s
Y = X %*% beta_true + rnorm(n)
beta = matrix(rep(0, p), nrow = p)
beta_all = matrix(rep(0, p*L), nrow = p)
err = rep(0, L)
R = Y
ss = rep(0, p)
for (j in 1:p)
ss[j] = sum(X[, j]^2)
for (l in 1:L)
{
lambda = lambda_all[l]
for (t in 1:T)
{
for (j in 1:p)
{
db = sum(R*X[, j])/ss[j]
b = beta[j]+db
b=sign(b)*max(0,abs(b)-lambda/ss[j])
db=b-beta[j]
R=R-X[,j]*db
beta[j]=b
}
}
beta_all[, l] = beta
err[l] = sum((beta-beta_true)^2)
}
par(mfrow=c(1,3))
matplot(t(matrix(rep(1, p), nrow = 1)%*%abs(beta_all)), t(beta_all), type = 'l',main='LASSO BOOSTING',xlab='N',ylab='Beta')
plot(lambda_all, err, type = 'l',main='LASSO ERROR ESTIMATION',xlab='Lambda',ylab='Error')
T = 6000
epsilon = .0001
beta = matrix(rep(0, p), nrow = p)
db = matrix(rep(0, p), nrow = p)
beta_all = matrix(rep(0, p*T), nrow = p)
R = Y
for (t in 1:T)
{
for (j in 1:p){
db[j] = sum(R*X[,j])
}
j=which.max(abs(db))
beta[j]=beta[j]+db[j]*epsilon
R=R-X[,j]*db[j]*epsilon
beta_all[,t] = beta
}
matplot(t(matrix(rep(1, p), nrow = 1)%*%abs(beta_all)), t(beta_all), type = 'l',main='STAGEWISE REGRESSION',xlab='N',ylab='Beta')
n = 50
p = 200
s = 10
T = 10
lambda_all = (100:1)*10
L = length(lambda_all)
db = matrix(rep(0, p), nrow = p)
X = matrix(rnorm(n*p), nrow=n)
beta_true = matrix(rep(0, p), nrow = p)
beta_true[1:s] = 1:s
Y = X %*% beta_true + rnorm(n)
beta = matrix(rep(0, p), nrow = p)
beta_all = matrix(rep(0, p*L), nrow = p)
err = rep(0, L)
R = Y
ss = rep(0, p)
for (j in 1:p)
ss[j] = sum(X[, j]^2)
for (l in 1:L)
{
lambda = lambda_all[l]
for (t in 1:T)
{
for (j in 1:p)
{
db = sum(R*X[, j])/ss[j]
b = beta[j]+db
b=sign(b)*max(0,abs(b)-lambda/ss[j])
db=b-beta[j]
R=R-X[,j]*db
beta[j]=b
}
}
beta_all[, l] = beta
err[l] = sum((beta-beta_true)^2)
}
par(mfrow=c(1,3))
matplot(t(matrix(rep(1, p), nrow = 1)%*%abs(beta_all)), t(beta_all), type = 'l',main='LASSO BOOSTING',xlab='N',ylab='Beta')
plot(lambda_all, err, type = 'l',main='LASSO ERROR ESTIMATION',xlab='Lambda',ylab='Error')
T = 6000
epsilon = .0001
beta = matrix(rep(0, p), nrow = p)
db = matrix(rep(0, p), nrow = p)
beta_all = matrix(rep(0, p*T), nrow = p)
R = Y
for (t in 1:T)
{
for (j in 1:p){
db[j] = sum(R*X[,j])
}
j=which.max(abs(db))
beta[j]=beta[j]+db[j]*epsilon
R=R-X[,j]*db[j]*epsilon
beta_all[,t] = beta
}
matplot(t(matrix(rep(1, p), nrow = 1)%*%abs(beta_all)), t(beta_all), type = 'l',main='STAGEWISE REGRESSION',xlab='N',ylab='Beta')
n = 50
p = 200
s = 10
T = 10
lambda_all = (100:1)*10
L = length(lambda_all)
db = matrix(rep(0, p), nrow = p)
X = matrix(rnorm(n*p), nrow=n)
beta_true = matrix(rep(0, p), nrow = p)
beta_true[1:s] = 1:s
Y = X %*% beta_true + rnorm(n)
beta = matrix(rep(0, p), nrow = p)
beta_all = matrix(rep(0, p*L), nrow = p)
err = rep(0, L)
R = Y
ss = rep(0, p)
for (j in 1:p)
ss[j] = sum(X[, j]^2)
for (l in 1:L)
{
lambda = lambda_all[l]
for (t in 1:T)
{
for (j in 1:p)
{
db = sum(R*X[, j])/ss[j]
b = beta[j]+db
b=sign(b)*max(0,abs(b)-lambda/ss[j])
db=b-beta[j]
R=R-X[,j]*db
beta[j]=b
}
}
beta_all[, l] = beta
err[l] = sum((beta-beta_true)^2)
}
par(mfrow=c(1,3))
matplot(t(matrix(rep(1, p), nrow = 1)%*%abs(beta_all)), t(beta_all), type = 'l',main='LASSO BOOSTING',xlab='N',ylab='Beta')
plot(lambda_all, err, type = 'l',main='LASSO ERROR ESTIMATION',xlab='Lambda',ylab='Error')
T = 6000
epsilon = .0001
beta = matrix(rep(0, p), nrow = p)
db = matrix(rep(0, p), nrow = p)
beta_all = matrix(rep(0, p*T), nrow = p)
R = Y
for (t in 1:T)
{
for (j in 1:p){
db[j] = sum(R*X[,j])
}
j=which.max(abs(db))
beta[j]=beta[j]+db[j]*epsilon
R=R-X[,j]*db[j]*epsilon
beta_all[,t] = beta
}
matplot(t(matrix(rep(1, p), nrow = 1)%*%abs(beta_all)), t(beta_all), type = 'l',main='STAGEWISE REGRESSION',xlab='N',ylab='Beta')
"
Name: Salil Kanetkar
UCLA ID: 704557096
HW 8 Submission
"
n = 50
p = 200
s = 10
T = 10
lambda_all = (100:1)*10
L = length(lambda_all)
db = matrix(rep(0, p), nrow = p)
X = matrix(rnorm(n*p), nrow=n)
beta_true = matrix(rep(0, p), nrow = p)
beta_true[1:s] = 1:s
Y = X %*% beta_true + rnorm(n)
beta = matrix(rep(0, p), nrow = p)
beta_all = matrix(rep(0, p*L), nrow = p)
err = rep(0, L)
R = Y
ss = rep(0, p)
for (j in 1:p)
ss[j] = sum(X[, j]^2)
for (l in 1:L)
{
lambda = lambda_all[l]
for (t in 1:T)
{
for (j in 1:p)
{
db = sum(R*X[, j])/ss[j]
b = beta[j]+db
b=sign(b)*max(0,abs(b)-lambda/ss[j])
db=b-beta[j]
R=R-X[,j]*db
beta[j]=b
}
}
beta_all[, l] = beta
err[l] = sum((beta-beta_true)^2)
}
par(mfrow=c(1,3))
matplot(t(matrix(rep(1, p), nrow = 1)%*%abs(beta_all)), t(beta_all), type = 'l',main='LASSO BOOSTING',xlab='N',ylab='Beta')
plot(lambda_all, err, type = 'l',main='LASSO ERROR ESTIMATION',xlab='Lambda',ylab='Error')
T = 6000
epsilon = .0001
beta = matrix(rep(0, p), nrow = p)
db = matrix(rep(0, p), nrow = p)
beta_all = matrix(rep(0, p*T), nrow = p)
R = Y
for (t in 1:T)
{
for (j in 1:p){
db[j] = sum(R*X[,j])
}
j=which.max(abs(db))
beta[j]=beta[j]+db[j]*epsilon
R=R-X[,j]*db[j]*epsilon
beta_all[,t] = beta
}
matplot(t(matrix(rep(1, p), nrow = 1)%*%abs(beta_all)), t(beta_all), type = 'l',main='STAGEWISE REGRESSION',xlab='N',ylab='Beta')
X <- matrxi(nrow=100,ncol=3)
X <- matrix(nrow=100,ncol=3)
x[:,1] <- 1
x[,1] <- 1
X[,1] <- 1
View(X)
View(X)
X[,2] <- rnorm(100)
View(X)
X[,2:3] <- rnorm(100)
View(X)
X <- matrix(nrow=100,ncol=3)
X[,1] <- 1
X[,2] <- rnorm(100)
X[,3] <- rnorm(100)
View(X)
beta <- matrix(c(1,2,3),nrow=3,ncol=1)
View(beta)
View(beta)
epsilon = rnorm(1, mean = 0, sd = 1)
epsilon = rnorm(1, mean = 0, sd = 1)
epsilon = rnorm(1, mean = 0, sd = 1)
epsilon = rnorm(1, mean = 0, sd = 1)
epsilon = rnorm(1, mean = 0, sd = 1)
Y = (X %*% beta) + epsilon
install.packages("mass")
install.packages("MASS")
beta_cap_ols = ginv(t(X) %*% X) %*% (t(X) %*% Y)
library("MASS")
beta_cap_ols = ginv(t(X) %*% X) %*% (t(X) %*% Y)
lm_beta = lm(Y ~ X)
lm_beta = lm(Y ~ X)$coefficients
lm_beta = lm(Y ~ 0+ X)$coefficients
library("MASS")
X = matrix(nrow=100,ncol=3)
X[,1] = 1
X[,2] = rnorm(100)
X[,3] = rnorm(100)
beta = matrix(c(1,2,3),nrow=3,ncol=1)
epsilon = rnorm(1, mean = 0, sd = 1)
Y = (X %*% beta) + epsilon
beta_cap_ols = ginv(t(X) %*% X) %*% (t(X) %*% Y)
lm_beta = lm(Y ~ 0 + X)$coefficients
setwd("H:/UCLA Winter 2016/201B - Statistical Modeling and Learning/Project/RCode")
penloss=function(par,X,S,Y,lambda){
Pword=dim(X)[2]
Psearch=dim(S)[2]
Uhat=matrix(par, nrow=Pword, ncol=Psearch)
Yhat=diag((X%*%Uhat)%*%t(S))
loss=sum((Y-Yhat)^2)
penalty=lambda*sum(sum(par^2))
return(loss)
}
svd_search <- read.csv("H:/UCLA Winter 2016/201B - Statistical Modeling and Learning/Project/RCode/svd_search.csv", header=FALSE)
View(svd_search)
svd_title_description <- read.csv("H:/UCLA Winter 2016/201B - Statistical Modeling and Learning/Project/RCode/svd_title_description.csv", header=FALSE)
View(svd_title_description)
Y_train <- read.table("H:/UCLA Winter 2016/201B - Statistical Modeling and Learning/Project/RCode/Y_train.csv", quote="\"", comment.char="")
View(Y_train)
lambda = 0.1
Pword = dim(svd_title_description[1000,])[2]
Pword = dim(svd_title_description[1:1000,])[2]
lambda = 0.1
Pword = dim(svd_title_description[1:1000,])[2]
PWord
Pword
lambda = 0.1
Pword = dim(svd_title_description[1:1000,])[2]
Psearch = dim(svd_search[1:1000,])[2]
opt.out=optim(par = rep(0,Psearch*Pword), method="Nelder-Mead",fn = penloss, X=as.matrix(svd_title_description[1:1000,]), S=as.matrix(svd_search[1:1000,]), Y=as.matrix(Y_train[1:1000]), lambda=lambda)
_train[1:1000]
Y_train[1:1000]
Y_train[1]
Y_train[1,1]
View(Y_train)
Y_train[1,1:1000]
Y_train[1,2]
Y_train[2,1]
Y_train[1:1000,1]
opt.out=optim(par = rep(0,Psearch*Pword), method="Nelder-Mead",fn = penloss, X=as.matrix(svd_title_description[1:1000,]), S=as.matrix(svd_search[1:1000,]), Y=as.matrix(Y_train[1:1000,1]), lambda=lambda)
Uhat.opt=matrix(opt.out$par,nrow=Pword, ncol=Psearch)
yhat.opt=diag(svd_title_description[1:1000,]%*%Uhat.opt%*%t(svd_search[1:1000,]))
yhat.opt=diag(as.matrix(svd_title_description[1:1000,])%*%Uhat.opt%*%t(as.matrix(svd_search[1:1000,])))
cor(Y,yhat.opt)^2
cor(Y_train,yhat.opt)^2
cor(as.matrix(Y_train),yhat.opt)^2
cor(as.matrix(Y_train[1:1000,1]),yhat.opt)^2
cor(Y_train[1:1000,1],yhat.opt)^2
View(svd_search)
scale(Y_train[1:1000,1])
opt.out=optim(par = rep(0,Psearch*Pword), method="Nelder-Mead",fn = penloss, X=as.matrix(svd_title_description[1:1000,]), S=as.matrix(svd_search[1:1000,]), Y=as.matrix(scale(Y_train[1:1000,1])), lambda=lambda)
yhat_opt_without_scaling = yhat.opt
Uhat.opt=matrix(opt.out$par,nrow=Pword, ncol=Psearch)
yhat.opt=diag(as.matrix(svd_title_description[1:1000,])%*%Uhat.opt%*%t(as.matrix(svd_search[1:1000,])))
yhat_opt_with_scaling = yhat.opt
cor(Y_train[1:1000,1],yhat.opt)^2
test_svd_title_description <- read.csv("H:/UCLA Winter 2016/201B - Statistical Modeling and Learning/Project/RCode/test_svd_title_description.csv", header=FALSE)
View(test_svd_title_description)
View(svd_search)
View(svd_title_description)
View(svd_title_description)
yhat.opt_test=diag(as.matrix(test_svd_title_description[1:1000,])%*%Uhat.opt%*%t(as.matrix(test_svd_search[1:1000,])))
test_svd_search <- read.csv("H:/UCLA Winter 2016/201B - Statistical Modeling and Learning/Project/RCode/test_svd_search.csv", header=FALSE)
View(test_svd_search)
yhat.opt_test=diag(as.matrix(test_svd_title_description[1:1000,])%*%Uhat.opt%*%t(as.matrix(test_svd_search[1:1000,])))
